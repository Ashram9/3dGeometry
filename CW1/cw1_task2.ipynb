{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: CORE SECTION (ICP Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found resources\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "# Path to Resources and Python Libraries\n",
    "RES_PATH = './bunny/data'\n",
    "LIB_PATH = './python_lib'\n",
    "\n",
    "# Checking if the path is found locally\n",
    "if not os.path.exists(RES_PATH):\n",
    "    print( 'cannot find mesh resources dir, please update RES_PATH')\n",
    "    exit(1)\n",
    "else:\n",
    "    print('found resources')\n",
    "\n",
    "# Loading Geo Tools\n",
    "sys.path.append(LIB_PATH) \n",
    "from geo_tools import rd_helper\n",
    "\n",
    "# Loading libraries for visualisation\n",
    "import pyglet\n",
    "pyglet.options['shadow_window'] = False\n",
    "import pyrender\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading libraries for basic geometry processing\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement ICP Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icp(M1, M2, max_iterations=100, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Perform Iterative Closest Point (ICP) algorithm to align M2 to M1.\n",
    "\n",
    "    Args:\n",
    "    - M1: numpy array representing the vertices of model M1 (shape: Nx3)\n",
    "    - M2: numpy array representing the vertices of model M2 (shape: Nx3)\n",
    "    - max_iterations: maximum number of iterations for ICP algorithm\n",
    "    - tolerance: convergence threshold\n",
    "\n",
    "    Returns:\n",
    "    - R: 3x3 rotation matrix\n",
    "    - t: 3x1 translation vector\n",
    "    - registered_models: list of models after each iteration (as trimesh.pointcloud.PointCloud objects)\n",
    "    \"\"\"\n",
    "\n",
    "    M1_vertices = M1.vertices.copy()\n",
    "    M2_vertices = M2.vertices.copy()\n",
    "\n",
    "    # Initialize rotation matrix R and translation vector t\n",
    "    R = np.eye(3)\n",
    "    t = np.zeros((3, 1))\n",
    "\n",
    "    # Initialize list to store registered models\n",
    "    registered_models = []\n",
    "\n",
    "    for iteration in range(1, max_iterations+1):\n",
    "        # Find the nearest neighbors between M1 and transformed M2\n",
    "        tree = KDTree(M1_vertices)\n",
    "        _, indices = tree.query(M2_vertices)\n",
    "\n",
    "        # Extract corresponding points from M1 and M2\n",
    "        P = M1_vertices[indices].squeeze()\n",
    "        Q = M2_vertices\n",
    "\n",
    "        # Compute the centroid of the matched points\n",
    "        centroid_P = np.mean(P, axis=0, keepdims=True)  #(1, 3)\n",
    "        centroid_Q = np.mean(Q, axis=0, keepdims=True)  #(1, 3)\n",
    "\n",
    "        # Compute the cross-covariance matrix\n",
    "        A = (Q - centroid_Q).T @ (P - centroid_P)   #(3, n) x (n, 3)\n",
    "\n",
    "        # Use Singular Value Decomposition (SVD) to compute the optimal rotation matrix R\n",
    "        U, _, Vt = np.linalg.svd(A)\n",
    "        R = Vt.T @ np.diag([1, 1, np.linalg.det(Vt.T @ U.T)]) @ U.T\n",
    "\n",
    "        # Compute the optimal translation vector t\n",
    "        t = centroid_P.T - R @ centroid_Q.T\n",
    "\n",
    "        # Apply transformation to M2 for the next iteration and store the result\n",
    "        M2_vertices = (R @ M2_vertices.T + t).T\n",
    "        registered_model = trimesh.points.PointCloud(M2_vertices)\n",
    "        registered_models.append(registered_model)\n",
    "\n",
    "        # Check convergence\n",
    "        if np.linalg.norm(t) < tolerance:\n",
    "            print('Converge at iteration', iteration)\n",
    "            break\n",
    "\n",
    "    if iteration == max_iterations:\n",
    "        print(iteration, 'the iteration reached maximum.')\n",
    "    \n",
    "    return R, t, registered_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the point cloud model M1 and M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1 shape of Vertices: (40256, 3)\n",
      "M2 shape of Vertices: (40097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Loading the point cloud model M1 and M2\n",
    "mesh_fp1 = os.path.join(RES_PATH,'bun000.ply')\n",
    "assert os.path.exists(mesh_fp1), 'Cannot find:' + mesh_fp1\n",
    "M1 = trimesh.load(mesh_fp1)\n",
    "print('M1 shape of Vertices:', M1.vertices.shape)\n",
    "\n",
    "mesh_fp2 = os.path.join(RES_PATH,'bun045.ply')\n",
    "assert os.path.exists(mesh_fp2), 'Cannot find:' + mesh_fp2\n",
    "M2 = trimesh.load(mesh_fp2)\n",
    "print('M2 shape of Vertices:', M2.vertices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ICP algorithm to do local registration from M2 to M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converge at iteration 60\n"
     ]
    }
   ],
   "source": [
    "# Conduct ICP algorithm...\n",
    "R, t, registered_models = icp(M1, M2)\n",
    "\n",
    "# Save registered models\n",
    "for i, model in enumerate(registered_models):\n",
    "        directory = './results_task2/standard_ICP_results/'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = f\"registered_model_{i+1}.ply\"\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        model.export(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ply\\nformat binary_little_endian 1.0\\ncomment https://github.com/mikedh/trimesh\\nelement vertex 0\\nproperty float x\\nproperty float y\\nproperty float z\\nproperty uchar red\\nproperty uchar green\\nproperty uchar blue\\nproperty uchar alpha\\nend_header\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find non-overlapping points (after alignment)\n",
    "registered_M2 = registered_models[-1]\n",
    "tree = KDTree(M1.vertices)\n",
    "distances, _ = tree.query(registered_M2.vertices)\n",
    "non_overlapping_indices = np.where(np.isnan(distances))[0]\n",
    "non_overlapping_points = registered_M2.vertices[non_overlapping_indices]\n",
    "# Save non-overlapping points to a PLY file\n",
    "trimesh.points.PointCloud(non_overlapping_points).export('./results_task2/standard_ICP_results/non_overlapping_points.ply')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check performance with perturbation\n",
    "a) Assume that the model M1 is at the origin (i.e., centroid of M1 is at the origin). Now assume M2 = R(M1), i.e., a rotated version of model M1 about the origin. Progressively perturb the initial rotation of R and evaluate the convergence behavior of ICP trying to align M2 → M1. R can be rotation about any of the coordinate axes for example. One way to simulate the effect of increasing misalignment (i.e., initial alignment) is to rotate the object about z-axis over increasing rotation angles (say ±5, ±10, ±15,.. degrees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rotation_matrix(angle):\n",
    "    \"\"\"\n",
    "    Generate a rotation matrix for rotating around the z-axis by the given angle.\n",
    "\n",
    "    Args:\n",
    "    - angle: rotation angle in degrees\n",
    "\n",
    "    Returns:\n",
    "    - R: 3x3 rotation matrix\n",
    "    \"\"\"\n",
    "    angle_rad = np.radians(angle)\n",
    "    cos_theta = np.cos(angle_rad)\n",
    "    sin_theta = np.sin(angle_rad)\n",
    "    R = np.array([[cos_theta, -sin_theta, 0],\n",
    "                  [sin_theta, cos_theta, 0],\n",
    "                  [0, 0, 1]])\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturb 5 degree...\n",
      "Converge at iteration 19\n",
      "Perturb 10 degree...\n",
      "Converge at iteration 25\n",
      "Perturb 15 degree...\n",
      "Converge at iteration 28\n"
     ]
    }
   ],
   "source": [
    "# Initialse model M1 at origin\n",
    "M1_origin = M1.copy()\n",
    "centroid_M1 = np.mean(M1_origin.vertices, axis=0, keepdims=True)  #(1, 3)\n",
    "M1_origin.vertices = M1_origin.vertices - centroid_M1\n",
    "directory = f'./results_task2/perturb_results/perturb by rotation/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "filename = f\"M1_origin.ply\"\n",
    "filepath = os.path.join(directory, filename)\n",
    "M1_origin.export(filepath)\n",
    "\n",
    "# Increase rotation angle progressively\n",
    "perturb_angles = [5, 10, 15]    \n",
    "for angle in perturb_angles:\n",
    "    M2_origin = M1_origin.copy()\n",
    "    print('Perturb', angle, 'degree...')\n",
    "    # Generate rotation matrix for current angle\n",
    "    R = generate_rotation_matrix(angle)\n",
    "\n",
    "    # Rotate model M1 to generate model M2\n",
    "    M2_origin.vertices = (R @ M1_origin.vertices.T).T\n",
    "\n",
    "    # Run ICP to align M2 to M1\n",
    "    _, _, registered_models = icp(M1_origin, M2_origin)\n",
    "\n",
    "    for i, model in enumerate(registered_models):\n",
    "        directory = f'./results_task2/perturb_results/perturb by rotation/perturb {angle} degree/'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = f\"registered_model_{i+1}.ply\"\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        model.export(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Perturb model M2 (without the extra rotation) to simulate a noisy model say M2'. Evaluate how well ICP\n",
    "performs as you continue to add more noise. As for noise, add zero-mean Gaussian noise – you can simply\n",
    "perturb each vertex of the mesh M2 under this Gaussian model. Adjust the amount of noise based on the\n",
    "bounding box dimensions of M2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturb 0.001174210011959076 std...\n",
      "Converge at iteration 11\n",
      "Perturb 0.002348420023918152 std...\n",
      "Converge at iteration 19\n",
      "Perturb 0.004696840047836304 std...\n",
      "Converge at iteration 26\n"
     ]
    }
   ],
   "source": [
    "# Initialse model M1 at origin\n",
    "M1_origin = M1.copy()\n",
    "centroid_M1 = np.mean(M1_origin.vertices, axis=0, keepdims=True)  #(1, 3)\n",
    "M1_origin.vertices = M1_origin.vertices - centroid_M1\n",
    "\n",
    "# Increase std of Gaussian noise distribution progressively\n",
    "noise_stddev_scales = [0.01, 0.02, 0.04]\n",
    "for noise_stddev_scale in noise_stddev_scales:\n",
    "    M2_origin = M1_origin.copy()\n",
    "    # Perturb model M2 with Gaussian noise\n",
    "    noise_scale = noise_stddev_scale * np.min(M1_origin.bounding_box.extents)  # Adjust the amount of noise based on bounding box dimensions\n",
    "    M2_origin.vertices += np.random.normal(0, noise_scale, M2_origin.vertices.shape)\n",
    "    print('Perturb', noise_scale, 'std...')\n",
    "\n",
    "    # Run ICP to align M2_perturbed to M1\n",
    "    _, _, registered_models = icp(M1_origin, M2_origin)\n",
    "\n",
    "    for i, model in enumerate(registered_models):\n",
    "        directory = f'./results_task2/perturb_results/perturb by noise/Gaussian (std = {noise_scale})/'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = f\"registered_model_{i+1}.ply\"\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        model.export(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check performance with subsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of directly aligning M2 to M1, speed up your computation by estimating the aligning transform using subsampled versions of M1 and/or M2 as appropriate. Report accuracy with increasing subsampling rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icp_with_subsampling(M1, M2, subsample_rate, max_iterations=100, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Perform Iterative Closest Point (ICP) algorithm with subsampling to align M2 to M1.\n",
    "\n",
    "    Args:\n",
    "    - M1: numpy array representing the vertices of model M1 (shape: Nx3)\n",
    "    - M2: numpy array representing the vertices of model M2 (shape: Nx3)\n",
    "    - subsample_rate: subsampling rate (between 0 and 1)\n",
    "    - max_iterations: maximum number of iterations for ICP algorithm\n",
    "    - tolerance: convergence threshold\n",
    "\n",
    "    Returns:\n",
    "    - R: 3x3 rotation matrix\n",
    "    - t: 3x1 translation vector\n",
    "    - registered_models: list of models after each iteration (as trimesh.pointcloud.PointCloud objects)\n",
    "    \"\"\"\n",
    "\n",
    "    # Subsample M1 and M2\n",
    "    M1_vertices = M1.vertices.copy()[::int(1/subsample_rate)]\n",
    "    M2_vertices = M2.vertices.copy()[::int(1/subsample_rate)]\n",
    "\n",
    "    # Initialize rotation matrix R and translation vector t\n",
    "    R = np.eye(3)\n",
    "    t = np.zeros((3, 1))\n",
    "\n",
    "    # Initialize list to store registered models\n",
    "    registered_models = []\n",
    "\n",
    "    for iteration in range(1, max_iterations+1):\n",
    "        # Find the nearest neighbors between subsampled M1 and transformed subsampled M2\n",
    "        tree = KDTree(M1_vertices)\n",
    "        _, indices = tree.query(M2_vertices)\n",
    "\n",
    "        # Extract corresponding points from subsampled M1 and M2\n",
    "        P = M1_vertices[indices].squeeze()\n",
    "        Q = M2_vertices\n",
    "\n",
    "        # Compute the centroid of the matched points\n",
    "        centroid_P = np.mean(P, axis=0, keepdims=True)  #(1, 3)\n",
    "        centroid_Q = np.mean(Q, axis=0, keepdims=True)  #(1, 3)\n",
    "\n",
    "        # Compute the cross-covariance matrix\n",
    "        A = (Q - centroid_Q).T @ (P - centroid_P)   #(3, n) x (n, 3)\n",
    "\n",
    "        # Use Singular Value Decomposition (SVD) to compute the optimal rotation matrix R\n",
    "        U, _, Vt = np.linalg.svd(A)\n",
    "        R = Vt.T @ np.diag([1, 1, np.linalg.det(Vt.T @ U.T)]) @ U.T\n",
    "\n",
    "        # Compute the optimal translation vector t\n",
    "        t = centroid_P.T - R @ centroid_Q.T\n",
    "\n",
    "        # Apply transformation to M2 for the next iteration and store the result\n",
    "        M2_vertices = (R @ M2_vertices.T + t).T\n",
    "        registered_model = trimesh.points.PointCloud(M2_vertices)\n",
    "        registered_models.append(registered_model)\n",
    "\n",
    "        # Check convergence\n",
    "        if np.linalg.norm(t) < tolerance:\n",
    "            print('Converge at iteration', iteration)\n",
    "            break\n",
    "\n",
    "    if iteration == max_iterations:\n",
    "        print(iteration, 'iterations complete.')\n",
    "\n",
    "    return R, t, registered_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample rate: 0.1\n",
      "Converge at iteration 41\n",
      "subsample rate: 0.3\n",
      "Converge at iteration 55\n",
      "subsample rate: 0.5\n",
      "Converge at iteration 42\n",
      "subsample rate: 0.7\n",
      "Converge at iteration 60\n",
      "subsample rate: 0.9\n",
      "Converge at iteration 60\n"
     ]
    }
   ],
   "source": [
    "# Define subsampling rates to test\n",
    "subsample_rates = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "# Run ICP with subsampling for each subsampling rate\n",
    "for subsample_rate in subsample_rates:\n",
    "    print('subsample rate:', subsample_rate)\n",
    "\n",
    "    _, _, registered_models = icp_with_subsampling(M1, M2, subsample_rate)\n",
    "\n",
    "    for i, model in enumerate(registered_models):\n",
    "        directory = f'./results_task2/subsampling_results/subsample_rate_{subsample_rate}/'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = f\"registered_model_{i+1}.ply\"\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        model.export(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registration with multiple scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now given multiple scans M1,M2,...M5 align all of them to a common global coordinate frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1 shape of Vertices: (40256, 3)\n",
      "M2 shape of Vertices: (40097, 3)\n",
      "M3 shape of Vertices: (30379, 3)\n",
      "M4 shape of Vertices: (40251, 3)\n",
      "M5 shape of Vertices: (31701, 3)\n",
      "[<trimesh.PointCloud(vertices.shape=(40256, 3), name=`bun000.ply`)>, <trimesh.PointCloud(vertices.shape=(40097, 3), name=`bun045.ply`)>, <trimesh.PointCloud(vertices.shape=(30379, 3), name=`bun090.ply`)>, <trimesh.PointCloud(vertices.shape=(40251, 3), name=`bun180.ply`)>, <trimesh.PointCloud(vertices.shape=(31701, 3), name=`bun270.ply`)>]\n"
     ]
    }
   ],
   "source": [
    "# Load point cloud models M1 ~ M5\n",
    "mesh_fp1 = os.path.join(RES_PATH,'bun000.ply')\n",
    "assert os.path.exists(mesh_fp1), 'Cannot find:' + mesh_fp1\n",
    "M1 = trimesh.load(mesh_fp1)\n",
    "print('M1 shape of Vertices:', M1.vertices.shape)\n",
    "\n",
    "mesh_fp2 = os.path.join(RES_PATH,'bun045.ply')\n",
    "assert os.path.exists(mesh_fp2), 'Cannot find:' + mesh_fp2\n",
    "M2 = trimesh.load(mesh_fp2)\n",
    "print('M2 shape of Vertices:', M2.vertices.shape)\n",
    "\n",
    "mesh_fp3 = os.path.join(RES_PATH,'bun090.ply')\n",
    "assert os.path.exists(mesh_fp3), 'Cannot find:' + mesh_fp3\n",
    "M3 = trimesh.load(mesh_fp3)\n",
    "print('M3 shape of Vertices:', M3.vertices.shape)\n",
    "\n",
    "mesh_fp4 = os.path.join(RES_PATH,'bun180.ply')\n",
    "assert os.path.exists(mesh_fp4), 'Cannot find:' + mesh_fp4\n",
    "M4 = trimesh.load(mesh_fp4)\n",
    "print('M4 shape of Vertices:', M4.vertices.shape)\n",
    "\n",
    "mesh_fp5 = os.path.join(RES_PATH,'bun270.ply')\n",
    "assert os.path.exists(mesh_fp5), 'Cannot find:' + mesh_fp5\n",
    "M5 = trimesh.load(mesh_fp5)\n",
    "print('M5 shape of Vertices:', M5.vertices.shape)\n",
    "\n",
    "# Create a list to store models to be registered\n",
    "models = [M1, M2, M3, M4, M5]\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_multiple_scans(scans, max_iterations=100, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Align multiple scans to a common global coordinate frame.\n",
    "\n",
    "    Args:\n",
    "    - scans: a list of numpy arrays representing the vertices of each scan (shape: [N_scan, Nx3])\n",
    "    - max_iterations: maximum number of iterations for ICP algorithm\n",
    "    - tolerance: tolerance for convergence\n",
    "\n",
    "    Returns:\n",
    "    - aligned_scans: a list of aligned scans (as trimesh.pointcloud.PointCloud objects)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize list to store aligned scans\n",
    "    aligned_scans = []\n",
    "    aligned_scans.append(scans[0])\n",
    "\n",
    "    for i, scan in enumerate(scans[1:], start=1):\n",
    "        print(f'Processing model M{i+1}...')\n",
    "        # Copy the vertices to avoid modifying the original data\n",
    "        scan_vertices = scan.vertices.copy()\n",
    "\n",
    "        # Set reference scan as the previous one\n",
    "        reference_scan = aligned_scans[i-1].vertices.copy()\n",
    "\n",
    "        # Initialize rotation matrix R and translation vector t\n",
    "        R = np.eye(3)\n",
    "        t = np.zeros((3, 1))\n",
    "\n",
    "        # Perform ICP to align the current scan to the reference scan\n",
    "        for iteration in range(1, max_iterations+1):\n",
    "            # Find the nearest neighbors between the current scan and the reference scan\n",
    "            tree = KDTree(reference_scan)\n",
    "            _, indices = tree.query(scan_vertices)\n",
    "\n",
    "            # Extract corresponding points from the reference scan and the current scan\n",
    "            P = reference_scan[indices].squeeze()\n",
    "            Q = scan_vertices\n",
    "\n",
    "            # Compute the centroid of the matched points\n",
    "            centroid_P = np.mean(P, axis=0, keepdims=True)  #(1, 3)\n",
    "            centroid_Q = np.mean(Q, axis=0, keepdims=True)  #(1, 3)\n",
    "\n",
    "            # Compute the cross-covariance matrix\n",
    "            A = (Q - centroid_Q).T @ (P - centroid_P)   #(3, n) x (n, 3)\n",
    "\n",
    "            # Use Singular Value Decomposition (SVD) to compute the optimal rotation matrix R\n",
    "            U, _, Vt = np.linalg.svd(A)\n",
    "            R = Vt.T @ np.diag([1, 1, np.linalg.det(Vt.T @ U.T)]) @U.T\n",
    "\n",
    "            # Compute the optimal translation vector t\n",
    "            t = centroid_P.T - R @ centroid_Q.T\n",
    "\n",
    "            # Apply transformation to the current scan for the next iteration\n",
    "            scan_vertices = (R @ scan_vertices.T + t).T\n",
    "\n",
    "            # Check convergence\n",
    "            if np.linalg.norm(t) < tolerance:\n",
    "                print('Converge at iteration', iteration)\n",
    "                break\n",
    "\n",
    "        if iteration == max_iterations:\n",
    "            print(iteration, 'iterations complete.')\n",
    "\n",
    "        # Store the aligned scan\n",
    "        aligned_scan = trimesh.points.PointCloud(scan_vertices)\n",
    "        aligned_scans.append(aligned_scan)\n",
    "\n",
    "    return aligned_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model M2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converge at iteration 60\n",
      "Processing model M3...\n",
      "Converge at iteration 90\n",
      "Processing model M4...\n",
      "100 iterations complete.\n",
      "Processing model M5...\n",
      "100 iterations complete.\n"
     ]
    }
   ],
   "source": [
    "aligned_scans = align_multiple_scans(models)\n",
    "\n",
    "for i, aligned_scan in enumerate(aligned_scans):\n",
    "    directory = './results_task2/multiple_scans/method1/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"registered_M{i+1}.ply\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    aligned_scan.export(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_multiple_scans_2(scans, max_iterations=100, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Align multiple scans to a common global coordinate frame.\n",
    "\n",
    "    Args:\n",
    "    - scans: a list of numpy arrays representing the vertices of each scan (shape: [N_scan, Nx3])\n",
    "    - max_iterations: maximum number of iterations for ICP algorithm\n",
    "    - tolerance: tolerance for convergence\n",
    "\n",
    "    Returns:\n",
    "    - aligned_scans: a list of aligned scans (as trimesh.pointcloud.PointCloud objects)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize list to store aligned scans\n",
    "    aligned_scans = []\n",
    "    aligned_scans.append(scans[0])\n",
    "\n",
    "    for i, scan in enumerate(scans[1:], start=1):\n",
    "        print(f'Processing model M{i+1}...')\n",
    "        # Copy the vertices to avoid modifying the original data\n",
    "        scan_vertices = scan.vertices.copy()\n",
    "\n",
    "        # Set reference scan as all the other scans\n",
    "        other_scans = scans[:i] + scans[i+1:]\n",
    "        reference_scan = np.concatenate([s.vertices.copy() for s in other_scans])\n",
    "\n",
    "        # Initialize rotation matrix R and translation vector t\n",
    "        R = np.eye(3)\n",
    "        t = np.zeros((3, 1))\n",
    "\n",
    "        # Perform ICP to align the current scan to the reference scan\n",
    "        for iteration in range(1, max_iterations+1):\n",
    "            # Find the nearest neighbors between the current scan and the reference scan\n",
    "            tree = KDTree(reference_scan)\n",
    "            _, indices = tree.query(scan_vertices)\n",
    "\n",
    "            # Extract corresponding points from the reference scan and the current scan\n",
    "            P = reference_scan[indices].squeeze()\n",
    "            Q = scan_vertices\n",
    "\n",
    "            # Compute the centroid of the matched points\n",
    "            centroid_P = np.mean(P, axis=0, keepdims=True)  #(1, 3)\n",
    "            centroid_Q = np.mean(Q, axis=0, keepdims=True)  #(1, 3)\n",
    "\n",
    "            # Compute the cross-covariance matrix\n",
    "            A = (Q - centroid_Q).T @ (P - centroid_P)   #(3, n) x (n, 3)\n",
    "\n",
    "            # Use Singular Value Decomposition (SVD) to compute the optimal rotation matrix R\n",
    "            U, _, Vt = np.linalg.svd(A)\n",
    "            R = Vt.T @ np.diag([1, 1, np.linalg.det(Vt.T @ U.T)]) @ U.T\n",
    "\n",
    "            # Compute the optimal translation vector t\n",
    "            t = centroid_P.T - R @ centroid_Q.T\n",
    "\n",
    "            # Apply transformation to the current scan for the next iteration\n",
    "            scan_vertices = (R @ scan_vertices.T + t).T\n",
    "\n",
    "            # Check convergence\n",
    "            if np.linalg.norm(t) < tolerance:\n",
    "                print('Converge at iteration', iteration)\n",
    "                break\n",
    "\n",
    "        if iteration == max_iterations:\n",
    "            print(iteration, 'iterations complete.')\n",
    "\n",
    "        # Store the aligned scan\n",
    "        aligned_scan = trimesh.points.PointCloud(scan_vertices)\n",
    "        aligned_scans.append(aligned_scan)\n",
    "\n",
    "    return aligned_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model M2...\n",
      "100 iterations complete.\n",
      "Processing model M3...\n",
      "100 iterations complete.\n",
      "Processing model M4...\n",
      "100 iterations complete.\n",
      "Processing model M5...\n",
      "100 iterations complete.\n"
     ]
    }
   ],
   "source": [
    "aligned_scans = align_multiple_scans_2(models)\n",
    "\n",
    "for i, aligned_scan in enumerate(aligned_scans):\n",
    "    directory = './results_task2/multiple_scans/method2/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"registered_M{i+1}.ply\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    aligned_scan.export(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-to-Plane ICP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assume that you have access to normals at each vertex of the meshes. Update your viewer to shade the models based on these normals. Now, use the normal information to improve the ICP performance. you are attempting to solve minimize the following objective function E(R,t) =∑i |(Rpi +t − qi) · nqi |2 instead of minimizing E(R,t) =∑i |(Rpi + t − qi)|2 as implemented in Q1. Note that points pi ∈ M1 and qi ∈ M2 with nqi denoting normal at point qi to the mesh M2. This method is commonly referred to point-to-plane ICP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstsq_plane_fitting(surface_points, k):\n",
    "    ### fill in this function. normals should have same dimension as surface_points (nx3)\n",
    "    ### k is the number of neighbours\n",
    "\n",
    "    num_points, _ = surface_points.shape\n",
    "    # Construct KDTree based on point samples\n",
    "    tree = KDTree(surface_points)\n",
    "    # Get k-neighbours' indices of each point (include itself)\n",
    "    _, indices = tree.query(surface_points, k)\n",
    "    # Initialise normals\n",
    "    normals = np.zeros([num_points, 3])\n",
    "    for point in range(num_points):\n",
    "        neighbours = surface_points[indices[point], :]\n",
    "        (a, b, c), residual, rank, s = np.linalg.lstsq(neighbours, np.ones([k]))\n",
    "        normal = (a, b, c)\n",
    "        nn = np.linalg.norm(normal)\n",
    "        normal /= nn\n",
    "        normals[point, :] = normal\n",
    "    \n",
    "    return normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/lp7_63n15cxf9p82nfqb28m40000gn/T/ipykernel_63951/3455697768.py:14: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  (a, b, c), residual, rank, s = np.linalg.lstsq(neighbours, np.ones([k]))\n"
     ]
    }
   ],
   "source": [
    "# Calculate normals of target model M1\n",
    "normals = lstsq_plane_fitting(M1.vertices.copy(), 3)\n",
    "# Store in a new .ply file for visualisation\n",
    "vertices = M1.vertices.copy()\n",
    "vertex_normals = normals\n",
    "\n",
    "# Create PLY header\n",
    "ply_header = (\n",
    "    \"ply\\n\"\n",
    "    \"format ascii 1.0\\n\"\n",
    "    \"element vertex {}\\n\"\n",
    "    \"property float x\\n\"\n",
    "    \"property float y\\n\"\n",
    "    \"property float z\\n\"\n",
    "    \"property float nx\\n\"\n",
    "    \"property float ny\\n\"\n",
    "    \"property float nz\\n\"\n",
    "    \"end_header\\n\"\n",
    ").format(len(vertices))\n",
    "\n",
    "# Write the vertex coordinates and normal vector to the PLY file\n",
    "with open(\"bun000_with_normals.ply\", \"w\") as f:\n",
    "    f.write(ply_header)\n",
    "    for i in range(len(vertices)):\n",
    "        f.write(\"{} {} {} {} {} {}\\n\".format(\n",
    "            vertices[i][0], vertices[i][1], vertices[i][2],\n",
    "            vertex_normals[i][0], vertex_normals[i][1], vertex_normals[i][2]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_matrix_A_and_b(P, Q, N):\n",
    "    num_points = P.shape[0]\n",
    "    A = np.zeros((num_points, 6))\n",
    "    b = np.zeros((num_points, 1))\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        p_x, p_y, p_z = P[i]\n",
    "        q_x, q_y, q_z = Q[i]\n",
    "        n_x, n_y, n_z = N[i]\n",
    "        A[i, :3] = [n_z * p_y - n_y * p_z, n_x * p_z - n_z * p_x, n_y * p_x - n_x * p_y]\n",
    "        A[i, 3:] = N[i]\n",
    "        b[i] = n_x * (q_x - p_x) + n_y * (q_y - p_y) + n_z * (q_z - p_z)\n",
    "    \n",
    "    return A, b\n",
    "\n",
    "def solve_for_transformation(A, b):\n",
    "\n",
    "    # Initialize rotation matrix R and translation vector t\n",
    "    R = np.eye(3)\n",
    "    t = np.zeros((3, 1))\n",
    "\n",
    "    # Solve least square estimation\n",
    "    # x = A†b (Moore-Penrose Inverse & SVD)\n",
    "    # x = [[alpha], [beta], [gamma], [tx], [ty], [tz]], size(6, 1)\n",
    "    x, _, _, _ = np.linalg.lstsq(A, b, rcond=None)  \n",
    "    \n",
    "    # Construct rotation matrix\n",
    "    [[alpha], [beta], [gamma]] = x[:3]\n",
    "    r1_1 = np.cos(gamma) * np.cos(beta)\n",
    "    r1_2 = -np.sin(gamma) * np.cos(alpha) + np.cos(gamma) * np.sin(beta) * np.sin(alpha)\n",
    "    r1_3 = np.sin(gamma) * np.sin(alpha) + np.cos(gamma) * np.sin(beta) * np.cos(alpha)\n",
    "    r2_1 = np.sin(gamma) * np.cos(beta)\n",
    "    r2_2 = np.cos(gamma) * np.cos(alpha) + np.sin(gamma) * np.sin(beta) * np.sin(alpha)\n",
    "    r2_3 = -np.cos(gamma) * np.sin(alpha) + np.sin(gamma) * np.sin(beta) * np.cos(alpha)\n",
    "    r3_1 = -np.sin(beta)\n",
    "    r3_2 = np.cos(beta) * np.sin(alpha)\n",
    "    r3_3 = np.cos(beta) * np.cos(alpha)\n",
    "    R = np.array([[r1_1, r1_2, r1_3],\n",
    "                  [r2_1, r2_2, r2_3],\n",
    "                  [r3_1, r3_2, r3_3]])\n",
    "\n",
    "    # Construct translation matrix\n",
    "    t = x[3:]\n",
    "\n",
    "    return R, t\n",
    "\n",
    "def point2plane_icp(M1, M2, max_iterations=100, tolerance=1e-6):\n",
    "\n",
    "    M1_vertices = M1.vertices.copy()\n",
    "    M2_vertices = M2.vertices.copy()\n",
    "\n",
    "    M1_normals = lstsq_plane_fitting(M1_vertices, 3)  # estimate normals of M1's vertices\n",
    "\n",
    "    # Initialize rotation matrix R and translation vector t\n",
    "    R = np.eye(3)\n",
    "    t = np.zeros((3, 1))\n",
    "    \n",
    "    # Initialize list to store registered models\n",
    "    registered_models = []\n",
    "\n",
    "    for iteration in range(1, max_iterations+1):\n",
    "        tree = KDTree(M1_vertices)\n",
    "        distances, indices = tree.query(M2_vertices)\n",
    "\n",
    "        # if np.mean(distances) < tolerance:\n",
    "        #     print(f'Convergence achieved after {iteration} iterations.')\n",
    "        #     break\n",
    "\n",
    "        P = M2_vertices\n",
    "        Q = M1_vertices[indices].squeeze()\n",
    "        N = M1_normals[indices].squeeze()\n",
    "\n",
    "        A, b = construct_matrix_A_and_b(P, Q, N)\n",
    "        R, t = solve_for_transformation(A, b)\n",
    "\n",
    "        # Check convergence\n",
    "        if np.linalg.norm(t) < tolerance:\n",
    "            print('Converge at iteration', iteration)\n",
    "            break\n",
    "        \n",
    "        M2_vertices = (R @ M2_vertices.T + t).T\n",
    "        registered_model = trimesh.points.PointCloud(M2_vertices)\n",
    "        registered_models.append(registered_model)\n",
    "\n",
    "    if iteration == max_iterations:\n",
    "        print(iteration, 'iterations complete.')\n",
    "\n",
    "    return R, t, registered_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/lp7_63n15cxf9p82nfqb28m40000gn/T/ipykernel_63951/3455697768.py:14: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  (a, b, c), residual, rank, s = np.linalg.lstsq(neighbours, np.ones([k]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converge at iteration 37\n"
     ]
    }
   ],
   "source": [
    "# Conduct point to plane algorithm...\n",
    "_, _, registered_models = point2plane_icp(M1, M2)\n",
    "\n",
    "# Save registered models\n",
    "for i, model in enumerate(registered_models):\n",
    "    directory = './results_task2/point2plane_ICP_results/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"registered_model_{i+1}.ply\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    model.export(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
